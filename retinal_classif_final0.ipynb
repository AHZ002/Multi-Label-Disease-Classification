{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import (Dense, GlobalAveragePooling2D, Conv2D,\n",
        "                                   Conv2DTranspose, Reshape, Add, Multiply,\n",
        "                                   MultiHeadAttention, LayerNormalization, Dropout,\n",
        "                                   Input, Concatenate)\n",
        "from tensorflow.keras.metrics import Recall, Precision, AUC\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# Install required packages for BioBERT\n",
        "try:\n",
        "    import transformers\n",
        "    from transformers import AutoTokenizer, TFAutoModel\n",
        "    print(\"Transformers library already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing transformers library...\")\n",
        "    os.system(\"pip install transformers\")\n",
        "    import transformers\n",
        "    from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "# Mount Google Drive (if using Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully\")\n",
        "except ImportError:\n",
        "    print(\"Not running in Colab, skipping drive mount\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_IqVfWvRpJQ",
        "outputId": "e82716c0-a675-4b31-9cbe-7496c8c5d8b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers library already installed\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BioBERT Disease Embedding Class\n",
        "class BioBERTDiseaseEmbedder:\n",
        "    \"\"\"Class to generate disease embeddings using BioBERT\"\"\"\n",
        "\n",
        "    def __init__(self, model_name='dmis-lab/biobert-base-cased-v1.1', embedding_dim=512):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.disease_embeddings = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load BioBERT tokenizer and model\"\"\"\n",
        "        print(\"Loading BioBERT model...\")\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            # Try loading with PyTorch conversion first\n",
        "            self.model = TFAutoModel.from_pretrained(self.model_name, from_pt=True)\n",
        "            print(\"BioBERT model loaded successfully (converted from PyTorch)\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading BioBERT model: {e}\")\n",
        "            print(\"Falling back to alternative biomedical model...\")\n",
        "            # Fallback to a model with native TensorFlow support\n",
        "            try:\n",
        "                self.model_name = 'bert-base-uncased'  # Fallback option\n",
        "                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "                self.model = TFAutoModel.from_pretrained(self.model_name)\n",
        "                print(\"Fallback model loaded successfully\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Fallback model also failed: {e2}\")\n",
        "                raise e2\n",
        "\n",
        "    def generate_disease_embeddings(self, disease_labels):\n",
        "        \"\"\"Generate embeddings for disease labels\"\"\"\n",
        "        if self.tokenizer is None or self.model is None:\n",
        "            self.load_model()\n",
        "\n",
        "        embeddings = []\n",
        "\n",
        "        print(\"Generating disease embeddings...\")\n",
        "        for disease in disease_labels:\n",
        "            # Tokenize the disease name\n",
        "            inputs = self.tokenizer(\n",
        "                disease,\n",
        "                return_tensors='tf',\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=64\n",
        "            )\n",
        "\n",
        "            # Get BioBERT embeddings\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "            # Use [CLS] token embedding (first token)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :]  # Shape: (1, 768)\n",
        "\n",
        "            embeddings.append(cls_embedding.numpy())\n",
        "\n",
        "        # Stack all embeddings\n",
        "        disease_embeddings = np.vstack(embeddings)  # Shape: (num_diseases, 768)\n",
        "\n",
        "        # Project to desired embedding dimension if needed\n",
        "        if disease_embeddings.shape[1] != self.embedding_dim:\n",
        "            projection_matrix = np.random.normal(\n",
        "                0, 0.02, (disease_embeddings.shape[1], self.embedding_dim)\n",
        "            )\n",
        "            disease_embeddings = disease_embeddings @ projection_matrix\n",
        "\n",
        "        self.disease_embeddings = disease_embeddings\n",
        "        print(f\"Disease embeddings generated: {disease_embeddings.shape}\")\n",
        "\n",
        "        return disease_embeddings"
      ],
      "metadata": {
        "id": "dtlJCyKERzZp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data extraction\n",
        "def extract_data():\n",
        "    \"\"\"Extract dataset from zip file\"\"\"\n",
        "    try:\n",
        "        with ZipFile(\"/content/drive/MyDrive/mured.zip\", 'r') as zip_file:\n",
        "            zip_file.extractall()\n",
        "            print(\"Data extraction completed\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Warning: Zip file not found. Please ensure data is available.\")\n",
        "\n",
        "# Data loading and preprocessing\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"Load and prepare training and test data\"\"\"\n",
        "    try:\n",
        "        # Load data\n",
        "        train_data = pd.read_csv('/content/drive/MyDrive/train_data_modified.csv')\n",
        "        test_data = pd.read_csv('/content/drive/MyDrive/test_data_modified.csv')\n",
        "\n",
        "        print(train_data.head())\n",
        "        print(test_data.head())\n",
        "\n",
        "        # Sample data for training (adjust as needed)\n",
        "        train_data = train_data.sample(frac=1, random_state=42)[:1600]\n",
        "        test_data = test_data[:320]\n",
        "\n",
        "        print(f\"Training data shape: {train_data.shape}\")\n",
        "        print(f\"Test data shape: {test_data.shape}\")\n",
        "\n",
        "        return train_data, test_data\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: CSV files not found. Please check file paths.\")\n",
        "        return None, None\n",
        "\n",
        "# Define disease labels\n",
        "DISEASE_LABELS = ['DR', 'NORMAL', 'MH', 'ODC', 'TSLN', 'ARMD', 'DN', 'MYA',\n",
        "                  'BRVO', 'ODP', 'CRVO', 'CNV', 'RS', 'ODE', 'LS', 'CSR',\n",
        "                  'HTR', 'ASR', 'CRS', 'OTHER']\n",
        "\n",
        "DISEASE_LABELS_FULL = ['DIABETIC RETINOPATHY', 'NORMAL', 'MEDIA HAZE',\n",
        "                       'OPTIC DISC COLOBOMA', 'TESSELLATION',\n",
        "                       'AGE RELATED MACULAR DEGENERATION', 'DRUSEN', 'MYOPIA',\n",
        "                       'BRANCH RETINAL VEIN OCCLUSION', 'OPTIC DISC PALLOR',\n",
        "                       'CENTRAL RETINAL VEIN OCCLUSION', 'CHOROIDAL NEOVASCULARIZATION',\n",
        "                       'RETINITIS', 'OPTIC DISC EDEMA', 'LASER SCARS',\n",
        "                       'CENTRAL SEROUS RETINOPATHY', 'HYPERTENSIVE RETINOPATHY',\n",
        "                       'ARTIFICIAL SILICON RETINA', 'CHORIORETINITIS', 'OTHER']"
      ],
      "metadata": {
        "id": "sQEDlV28R4l-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "def create_data_generators(train_data, test_data, batch_size=16, img_size=(320, 320)):\n",
        "    \"\"\"Create data generators for training, validation, and testing\"\"\"\n",
        "\n",
        "    # Training data generator with augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Test data generator (no augmentation)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        directory=\"/content/images/images\",\n",
        "        x_col=\"ID_2\",\n",
        "        y_col=DISEASE_LABELS,\n",
        "        class_mode='raw',\n",
        "        batch_size=batch_size,\n",
        "        target_size=img_size,\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    val_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        directory=\"/content/images/images\",\n",
        "        x_col=\"ID_2\",\n",
        "        y_col=DISEASE_LABELS,\n",
        "        class_mode='raw',\n",
        "        batch_size=batch_size,\n",
        "        target_size=img_size,\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_data,\n",
        "        directory=\"/content/images/images\",\n",
        "        x_col=\"ID_2\",\n",
        "        y_col=DISEASE_LABELS,\n",
        "        class_mode='raw',\n",
        "        batch_size=batch_size,\n",
        "        target_size=img_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "TgT1nd_dR77R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom layers\n",
        "class FullyConnectedLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Custom fully connected layer for transformer-like architecture\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, fully_connected_dim, dropout_rate=0.1, **kwargs):\n",
        "        super(FullyConnectedLayer, self).__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.fully_connected_dim = fully_connected_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.dense1 = Dense(fully_connected_dim, activation='relu')\n",
        "        self.dense2 = Dense(embedding_dim)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        return self.dense2(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embedding_dim\": self.embedding_dim,\n",
        "            \"fully_connected_dim\": self.fully_connected_dim,\n",
        "            \"dropout_rate\": self.dropout_rate\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Transformer encoder layer with multi-head attention\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
        "                 dropout_rate=0.1, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.fully_connected_dim = fully_connected_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.mha = MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=embedding_dim,\n",
        "            dropout=dropout_rate\n",
        "        )\n",
        "\n",
        "        self.ffn = FullyConnectedLayer(embedding_dim, fully_connected_dim, dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        # Multi-head attention\n",
        "        attn_output = self.mha(inputs, inputs, inputs, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "        # Feed forward network\n",
        "        ffn_output = self.ffn(out1, training=training)\n",
        "        encoder_output = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return encoder_output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embedding_dim\": self.embedding_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"fully_connected_dim\": self.fully_connected_dim,\n",
        "            \"dropout_rate\": self.dropout_rate\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "IUSMzoZbSDGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalMeanPoolingLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Custom layer for global mean pooling along sequence dimension\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(GlobalMeanPoolingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.reduce_mean(inputs, axis=1)\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "class DiseaseEmbeddingExpansionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer to expand disease embeddings based on batch size\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super(DiseaseEmbeddingExpansionLayer, self).__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs is a tuple of (batch_reference, disease_embeddings)\n",
        "        batch_reference, disease_embeddings = inputs\n",
        "        batch_size = tf.shape(batch_reference)[0]\n",
        "\n",
        "        # Expand disease embeddings to match batch size\n",
        "        expanded = tf.expand_dims(disease_embeddings, 0)\n",
        "        tiled = tf.tile(expanded, [batch_size, 1, 1])\n",
        "        return tiled\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"num_classes\": self.num_classes})\n",
        "        return config\n",
        "    \"\"\"Layer to provide BioBERT disease embeddings to the model\"\"\"\n",
        "\n",
        "class BioBERTDiseaseEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer to provide BioBERT disease embeddings to the model\"\"\"\n",
        "\n",
        "    def __init__(self, disease_embeddings, embedding_dim=512, **kwargs):\n",
        "        super(BioBERTDiseaseEmbeddingLayer, self).__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_classes = disease_embeddings.shape[0]\n",
        "\n",
        "        # Store disease embeddings as a weight (trainable parameter)\n",
        "        self.disease_embeddings_weight = None\n",
        "        self.disease_embeddings_np = disease_embeddings.astype(np.float32)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create the embeddings as a trainable weight\n",
        "        self.disease_embeddings_weight = self.add_weight(\n",
        "            name='disease_embeddings',\n",
        "            shape=(self.num_classes, self.embedding_dim),\n",
        "            initializer='zeros',\n",
        "            trainable=False  # Keep as non-trainable since they're pre-computed\n",
        "        )\n",
        "        # Initialize with BioBERT embeddings\n",
        "        self.disease_embeddings_weight.assign(self.disease_embeddings_np)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get batch size from input tensor\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Expand disease embeddings to match batch size\n",
        "        # Shape: (num_classes, embedding_dim) -> (batch_size, num_classes, embedding_dim)\n",
        "        expanded_embeddings = tf.expand_dims(self.disease_embeddings_weight, 0)\n",
        "        tiled_embeddings = tf.tile(expanded_embeddings, [batch_size, 1, 1])\n",
        "\n",
        "        return tiled_embeddings\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embedding_dim\": self.embedding_dim,\n",
        "            \"num_classes\": self.num_classes\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "MAP90xDRSS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model building functions\n",
        "def create_base_model(input_shape=(320, 320, 3)):\n",
        "    \"\"\"Create base DenseNet201 model\"\"\"\n",
        "    base_model = DenseNet201(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "    return base_model\n",
        "\n",
        "def create_multi_scale_features(base_model):\n",
        "    \"\"\"Create multi-scale feature extraction\"\"\"\n",
        "\n",
        "    # Get features from different layers\n",
        "    high_level_features = base_model.output  # Shape: (batch, 10, 10, 1920)\n",
        "    low_level_output = base_model.layers[-228].output  # Shape: (batch, 20, 20, 1792)\n",
        "\n",
        "    # Create models for different feature levels\n",
        "    low_level_model = Model(inputs=base_model.input, outputs=low_level_output)\n",
        "\n",
        "    # Multi-Scale Feature Module (MSFM)\n",
        "    f_h = Conv2D(512, (1, 1), activation='relu', name='high_level_conv')(high_level_features)\n",
        "    f_l = Conv2D(512, (1, 1), activation='relu', name='low_level_conv')(low_level_output)\n",
        "\n",
        "    # Upsample high-level features\n",
        "    f_up = Conv2DTranspose(512, kernel_size=(4, 4), strides=(2, 2),\n",
        "                          padding='same', activation='relu', name='upsample')(f_h)\n",
        "\n",
        "    # Combine features\n",
        "    f_combined = Add(name='feature_add')([f_up, f_l])\n",
        "    f_refined = Conv2D(512, 3, padding='same', activation='relu', name='refined_conv')(f_combined)\n",
        "\n",
        "    # Channel Attention Module (CAM)\n",
        "    f_gap = GlobalAveragePooling2D()(f_refined)\n",
        "    f_gap_reshaped = Reshape((1, 1, 512))(f_gap)\n",
        "\n",
        "    f_attention = Conv2D(512, (1, 1), activation='relu')(f_gap_reshaped)\n",
        "    f_attention = Conv2D(512, (1, 1), activation='sigmoid')(f_attention)\n",
        "\n",
        "    f_attended = Multiply()([f_refined, f_attention])\n",
        "    f_final = Add()([f_refined, f_attended])\n",
        "\n",
        "    return f_final, f_h"
      ],
      "metadata": {
        "id": "Ao12ud_-SdtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_biobert_enhanced_model(input_shape=(320, 320, 3), num_classes=20, disease_embeddings=None):\n",
        "    \"\"\"Create the complete model with BioBERT disease embeddings\"\"\"\n",
        "\n",
        "    # Input layer\n",
        "    image_input = Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Base DenseNet201 for visual features\n",
        "    base_model = DenseNet201(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Get visual features\n",
        "    visual_features = base_model(image_input)\n",
        "\n",
        "    # Multi-scale feature processing\n",
        "    f_h = Conv2D(512, (1, 1), activation='relu', name='high_level_conv')(visual_features)\n",
        "\n",
        "    # Try to get low-level features (with error handling)\n",
        "    try:\n",
        "        low_level_output = base_model.layers[-228].output\n",
        "        low_level_model = Model(inputs=base_model.input, outputs=low_level_output)\n",
        "        low_level_features = low_level_model(image_input)\n",
        "        f_l = Conv2D(512, (1, 1), activation='relu', name='low_level_conv')(low_level_features)\n",
        "\n",
        "        # Upsample high-level features\n",
        "        f_up = Conv2DTranspose(512, kernel_size=(4, 4), strides=(2, 2),\n",
        "                              padding='same', activation='relu', name='upsample')(f_h)\n",
        "\n",
        "        # Combine features\n",
        "        f_combined = Add(name='feature_add')([f_up, f_l])\n",
        "        f_refined = Conv2D(512, 3, padding='same', activation='relu', name='refined_conv')(f_combined)\n",
        "    except:\n",
        "        # Fallback: just use high-level features\n",
        "        print(\"Warning: Could not access low-level features, using high-level only\")\n",
        "        f_refined = Conv2D(512, 3, padding='same', activation='relu', name='refined_conv')(f_h)\n",
        "\n",
        "    # Global pooling to get visual feature vector\n",
        "    visual_pooled = GlobalAveragePooling2D(name='visual_gap')(f_refined)\n",
        "\n",
        "    # Reshape visual features for transformer: (batch_size, 1, 512)\n",
        "    visual_reshaped = Reshape((1, 512), name='visual_reshape')(visual_pooled)\n",
        "\n",
        "    # BioBERT Disease Embeddings\n",
        "    if disease_embeddings is not None:\n",
        "        # Create a constant layer for disease embeddings\n",
        "        disease_embeddings_const = tf.constant(disease_embeddings.astype(np.float32))\n",
        "\n",
        "        # Create a layer to expand disease embeddings based on batch size\n",
        "        class DiseaseEmbeddingLayer(tf.keras.layers.Layer):\n",
        "            def __init__(self, embeddings, **kwargs):\n",
        "                super().__init__(**kwargs)\n",
        "                self.embeddings = embeddings\n",
        "\n",
        "            def call(self, inputs):\n",
        "                batch_size = tf.shape(inputs)[0]\n",
        "                expanded = tf.expand_dims(self.embeddings, 0)\n",
        "                return tf.tile(expanded, [batch_size, 1, 1])\n",
        "\n",
        "            def get_config(self):\n",
        "                config = super().get_config()\n",
        "                config.update({\n",
        "                    \"embeddings\": self.embeddings.numpy().tolist()\n",
        "                })\n",
        "                return config\n",
        "\n",
        "            @classmethod\n",
        "            def from_config(cls, config):\n",
        "                embeddings = tf.constant(config.pop(\"embeddings\"))\n",
        "                return cls(embeddings, **config)\n",
        "\n",
        "        disease_embedding_layer = DiseaseEmbeddingLayer(disease_embeddings_const, name='disease_embeddings')\n",
        "        disease_features = disease_embedding_layer(image_input)\n",
        "    else:\n",
        "        # Fallback to learnable embeddings\n",
        "        embedding_layer = tf.keras.layers.Embedding(num_classes, 512, name='learnable_disease_embeddings')\n",
        "        indices = tf.range(num_classes)\n",
        "\n",
        "        # Create a layer to handle the embedding expansion\n",
        "        class DiseaseEmbeddingLayer(tf.keras.layers.Layer):\n",
        "            def __init__(self, embeddings, **kwargs):\n",
        "                super().__init__(**kwargs)\n",
        "                self.embeddings = embeddings\n",
        "\n",
        "            def call(self, inputs):\n",
        "                batch_size = tf.shape(inputs)[0]\n",
        "                expanded = tf.expand_dims(self.embeddings, 0)\n",
        "                return tf.tile(expanded, [batch_size, 1, 1])\n",
        "\n",
        "            def get_config(self):\n",
        "                config = super().get_config()\n",
        "                config.update({\n",
        "                    \"embeddings\": self.embeddings.numpy().tolist()\n",
        "                })\n",
        "                return config\n",
        "\n",
        "            @classmethod\n",
        "            def from_config(cls, config):\n",
        "                embeddings = tf.constant(config.pop(\"embeddings\"))\n",
        "                return cls(embeddings, **config)\n",
        "\n",
        "        learnable_layer = LearnableEmbeddingLayer(embedding_layer, indices, name='learnable_expansion')\n",
        "        disease_features = learnable_layer(image_input)\n",
        "\n",
        "    # Concatenate visual and disease features\n",
        "    combined_features = Concatenate(axis=1, name='feature_concat')([visual_reshaped, disease_features])\n",
        "\n",
        "    # Transformer encoder layers\n",
        "    transformer1 = EncoderLayer(\n",
        "        embedding_dim=512,\n",
        "        num_heads=8,\n",
        "        fully_connected_dim=2048,\n",
        "        dropout_rate=0.1,\n",
        "        name='transformer_encoder_1'\n",
        "    )\n",
        "    encoded_features1 = transformer1(combined_features)\n",
        "\n",
        "    # Second transformer layer\n",
        "    transformer2 = EncoderLayer(\n",
        "        embedding_dim=512,\n",
        "        num_heads=8,\n",
        "        fully_connected_dim=2048,\n",
        "        dropout_rate=0.1,\n",
        "        name='transformer_encoder_2'\n",
        "    )\n",
        "    encoded_features2 = transformer2(encoded_features1)\n",
        "\n",
        "    # Global pooling of all tokens using custom layer\n",
        "    global_pool = GlobalMeanPoolingLayer(name='global_mean_pool')\n",
        "    final_features = global_pool(encoded_features2)\n",
        "\n",
        "    # Classification head\n",
        "    x = Dense(1024, activation='relu', name='classifier_dense1')(final_features)\n",
        "    x = Dropout(0.5, name='classifier_dropout1')(x)\n",
        "    x = Dense(512, activation='relu', name='classifier_dense2')(x)\n",
        "    x = Dropout(0.3, name='classifier_dropout2')(x)\n",
        "    x = Dense(256, activation='relu', name='classifier_dense3')(x)\n",
        "    x = Dropout(0.2, name='classifier_dropout3')(x)\n",
        "\n",
        "    # Final predictions\n",
        "    predictions = Dense(num_classes, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "    # Create final model\n",
        "    model = Model(inputs=image_input, outputs=predictions, name='BioBERT_Medical_Classifier')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Q6ldhKZZSmn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_complete_model(input_shape=(320, 320, 3), num_classes=20, disease_embeddings=None):\n",
        "    \"\"\"Create the complete model with BioBERT integration\"\"\"\n",
        "    return create_biobert_enhanced_model(input_shape, num_classes, disease_embeddings)\n",
        "\n",
        "def compile_model(model, learning_rate=0.001):\n",
        "    \"\"\"Compile the model with appropriate optimizer and metrics\"\"\"\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            Precision(name='precision'),\n",
        "            Recall(name='recall'),\n",
        "            AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "r9GwqgO7Sq8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks(model_save_path='best_biobert_model.h5'):\n",
        "    \"\"\"Create training callbacks\"\"\"\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            model_save_path,\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return callbacks"
      ],
      "metadata": {
        "id": "_wmRvlrLSt6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_gen, val_gen, epochs=15, callbacks=None):\n",
        "    \"\"\"Train the model\"\"\"\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=len(train_gen),\n",
        "        epochs=epochs,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps=len(val_gen),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "nSPXTf16SxMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_gen):\n",
        "    \"\"\"Evaluate the model on test data\"\"\"\n",
        "\n",
        "    test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(\n",
        "        test_gen,\n",
        "        steps=len(test_gen),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Test Precision: {test_precision:.4f}\")\n",
        "    print(f\"Test Recall: {test_recall:.4f}\")\n",
        "    print(f\"Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'test_loss': test_loss,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'test_precision': test_precision,\n",
        "        'test_recall': test_recall,\n",
        "        'test_auc': test_auc\n",
        "    }"
      ],
      "metadata": {
        "id": "CWRXALw3S0Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution function\n",
        "def main():\n",
        "    \"\"\"Main function to run the complete pipeline with BioBERT\"\"\"\n",
        "\n",
        "    print(\"Starting Medical Image Classification Pipeline with BioBERT...\")\n",
        "\n",
        "    # Extract data\n",
        "    extract_data()\n",
        "\n",
        "    # Load and prepare data\n",
        "    train_data, test_data = load_and_prepare_data()\n",
        "    if train_data is None or test_data is None:\n",
        "        print(\"Failed to load data. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Generate BioBERT disease embeddings\n",
        "    print(\"Generating BioBERT disease embeddings...\")\n",
        "    biobert_embedder = BioBERTDiseaseEmbedder(embedding_dim=512)\n",
        "    disease_embeddings = biobert_embedder.generate_disease_embeddings(DISEASE_LABELS_FULL)\n",
        "\n",
        "    # Create data generators\n",
        "    train_gen, val_gen, test_gen = create_data_generators(train_data, test_data)\n",
        "\n",
        "    print(\"Data generators created successfully\")\n",
        "    print(f\"Training samples: {train_gen.n}\")\n",
        "    print(f\"Validation samples: {val_gen.n}\")\n",
        "    print(f\"Test samples: {test_gen.n}\")\n",
        "\n",
        "    # Create and compile model with BioBERT embeddings\n",
        "    print(\"Creating BioBERT-enhanced model...\")\n",
        "    model = create_complete_model(\n",
        "        input_shape=(320, 320, 3),\n",
        "        num_classes=20,\n",
        "        disease_embeddings=disease_embeddings\n",
        "    )\n",
        "    model = compile_model(model, learning_rate=0.0001)  # Lower learning rate for stability\n",
        "\n",
        "    print(\"Model created and compiled successfully\")\n",
        "    print(f\"Model parameters: {model.count_params():,}\")\n",
        "\n",
        "    # Print model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Create callbacks\n",
        "    callbacks = create_callbacks('best_biobert_medical_model.h5')\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    history = train_model(\n",
        "        model,\n",
        "        train_gen,\n",
        "        val_gen,\n",
        "        epochs=30,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"Evaluating model...\")\n",
        "    test_results = evaluate_model(model, test_gen)\n",
        "\n",
        "    print(\"Training completed successfully!\")\n",
        "    print(\"\\nArchitecture Summary:\")\n",
        "    print(\"1. Visual Features: DenseNet201 + Multi-scale features → 512-dim vectors\")\n",
        "    print(\"2. BioBERT Disease Embeddings → 512-dim vectors\")\n",
        "    print(\"3. Combined features fed to Transformer encoders\")\n",
        "    print(\"4. Final classification predictions\")\n",
        "\n",
        "    return model, history, test_results, disease_embeddings\n",
        "\n",
        "# Run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    model, history, results, embeddings = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MC5rSoF9L7jX",
        "outputId": "ca644a39-9e10-4ed8-d9b7-6b3252689d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers library already installed\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n",
            "Starting Medical Image Classification Pipeline with BioBERT...\n",
            "Data extraction completed\n",
            "Training data shape: (1600, 23)\n",
            "Test data shape: (320, 23)\n",
            "Generating BioBERT disease embeddings...\n",
            "Loading BioBERT model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BioBERT model loaded successfully (converted from PyTorch)\n",
            "Generating disease embeddings...\n",
            "Disease embeddings generated: (20, 512)\n",
            "Found 1280 validated image filenames.\n",
            "Found 320 validated image filenames.\n",
            "Found 320 validated image filenames.\n",
            "Data generators created successfully\n",
            "Training samples: 1280\n",
            "Validation samples: 320\n",
            "Test samples: 320\n",
            "Creating BioBERT-enhanced model...\n",
            "Model created and compiled successfully\n",
            "Model parameters: 48,512,340\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"BioBERT_Medical_Classifier\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BioBERT_Medical_Classifier\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ densenet201         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │ \u001b[38;5;34m18,321,984\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1920\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ high_level_conv     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │    \u001b[38;5;34m983,552\u001b[0m │ densenet201[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ functional          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m,    │ \u001b[38;5;34m11,238,464\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m896\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ upsample            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m,    │  \u001b[38;5;34m4,194,816\u001b[0m │ high_level_conv[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ low_level_conv      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m,    │    \u001b[38;5;34m459,264\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ feature_add (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ upsample[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │ low_level_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ refined_conv        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ feature_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ visual_gap          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ refined_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ visual_reshape      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ visual_gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ disease_embeddings  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDiseaseEmbeddingL…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ feature_concat      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ visual_reshape[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ disease_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │ \u001b[38;5;34m10,503,168\u001b[0m │ feature_concat[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEncoderLayer\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │ \u001b[38;5;34m10,503,168\u001b[0m │ transformer_enco… │\n",
              "│ (\u001b[38;5;33mEncoderLayer\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_mean_pool    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ transformer_enco… │\n",
              "│ (\u001b[38;5;33mGlobalMeanPooling…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dense1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │    \u001b[38;5;34m525,312\u001b[0m │ global_mean_pool… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dropout1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ classifier_dense… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dense2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m524,800\u001b[0m │ classifier_dropo… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dropout2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ classifier_dense… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dense3   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ classifier_dropo… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dropout3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ classifier_dense… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ predictions (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │      \u001b[38;5;34m5,140\u001b[0m │ classifier_dropo… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ densenet201         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ high_level_conv     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">983,552</span> │ densenet201[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ functional          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">11,238,464</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ upsample            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ high_level_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ low_level_conv      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">459,264</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ feature_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ upsample[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ low_level_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ refined_conv        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ feature_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ visual_gap          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ refined_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ visual_reshape      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ visual_gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ disease_embeddings  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiseaseEmbeddingL…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ feature_concat      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ visual_reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ disease_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,503,168</span> │ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,503,168</span> │ transformer_enco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_mean_pool    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_enco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMeanPooling…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dense1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ global_mean_pool… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dropout1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ classifier_dense… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dense2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ classifier_dropo… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dropout2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ classifier_dense… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dense3   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ classifier_dropo… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classifier_dropout3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ classifier_dense… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140</span> │ classifier_dropo… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,512,340\u001b[0m (185.06 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,512,340</span> (185.06 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,283,284\u001b[0m (184.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,283,284</span> (184.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m229,056\u001b[0m (894.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">229,056</span> (894.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1032 - auc: 0.6014 - loss: 0.3405 - precision: 0.0985 - recall: 0.1068"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.73143, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 3s/step - accuracy: 0.1036 - auc: 0.6018 - loss: 0.3397 - precision: 0.0988 - recall: 0.1062 - val_accuracy: 0.2125 - val_auc: 0.7314 - val_loss: 0.2097 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1448 - auc: 0.6640 - loss: 0.2435 - precision: 0.1326 - recall: 0.0215\n",
            "Epoch 2: val_auc improved from 0.73143 to 0.74545, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.1448 - auc: 0.6641 - loss: 0.2435 - precision: 0.1330 - recall: 0.0215 - val_accuracy: 0.2375 - val_auc: 0.7454 - val_loss: 0.2084 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1541 - auc: 0.6787 - loss: 0.2385 - precision: 0.2221 - recall: 0.0249\n",
            "Epoch 3: val_auc did not improve from 0.74545\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.1543 - auc: 0.6789 - loss: 0.2384 - precision: 0.2223 - recall: 0.0250 - val_accuracy: 0.2750 - val_auc: 0.7393 - val_loss: 0.2079 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1910 - auc: 0.7056 - loss: 0.2287 - precision: 0.2559 - recall: 0.0255\n",
            "Epoch 4: val_auc improved from 0.74545 to 0.75445, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3s/step - accuracy: 0.1914 - auc: 0.7058 - loss: 0.2286 - precision: 0.2568 - recall: 0.0257 - val_accuracy: 0.3406 - val_auc: 0.7544 - val_loss: 0.2053 - val_precision: 0.6818 - val_recall: 0.0758\n",
            "Epoch 5/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2598 - auc: 0.7478 - loss: 0.2175 - precision: 0.4206 - recall: 0.0773\n",
            "Epoch 5: val_auc improved from 0.75445 to 0.77716, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 3s/step - accuracy: 0.2600 - auc: 0.7478 - loss: 0.2175 - precision: 0.4211 - recall: 0.0774 - val_accuracy: 0.3625 - val_auc: 0.7772 - val_loss: 0.2011 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2982 - auc: 0.7653 - loss: 0.2112 - precision: 0.4811 - recall: 0.0648\n",
            "Epoch 6: val_auc improved from 0.77716 to 0.80519, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3s/step - accuracy: 0.2985 - auc: 0.7653 - loss: 0.2112 - precision: 0.4818 - recall: 0.0652 - val_accuracy: 0.4031 - val_auc: 0.8052 - val_loss: 0.1904 - val_precision: 0.5347 - val_recall: 0.1364\n",
            "Epoch 7/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3499 - auc: 0.7627 - loss: 0.2077 - precision: 0.4983 - recall: 0.1168\n",
            "Epoch 7: val_auc did not improve from 0.80519\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.3498 - auc: 0.7628 - loss: 0.2077 - precision: 0.4984 - recall: 0.1167 - val_accuracy: 0.3656 - val_auc: 0.7955 - val_loss: 0.1951 - val_precision: 0.6111 - val_recall: 0.0833\n",
            "Epoch 8/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3433 - auc: 0.7838 - loss: 0.2052 - precision: 0.5547 - recall: 0.1372\n",
            "Epoch 8: val_auc did not improve from 0.80519\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.3434 - auc: 0.7837 - loss: 0.2052 - precision: 0.5546 - recall: 0.1371 - val_accuracy: 0.3719 - val_auc: 0.8026 - val_loss: 0.1906 - val_precision: 0.6812 - val_recall: 0.1187\n",
            "Epoch 9/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3333 - auc: 0.7885 - loss: 0.2020 - precision: 0.5272 - recall: 0.1176\n",
            "Epoch 9: val_auc improved from 0.80519 to 0.82944, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 3s/step - accuracy: 0.3336 - auc: 0.7886 - loss: 0.2019 - precision: 0.5275 - recall: 0.1178 - val_accuracy: 0.4125 - val_auc: 0.8294 - val_loss: 0.1809 - val_precision: 0.6463 - val_recall: 0.1338\n",
            "Epoch 10/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3649 - auc: 0.8044 - loss: 0.1955 - precision: 0.5302 - recall: 0.1322\n",
            "Epoch 10: val_auc did not improve from 0.82944\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - accuracy: 0.3650 - auc: 0.8044 - loss: 0.1955 - precision: 0.5304 - recall: 0.1322 - val_accuracy: 0.4062 - val_auc: 0.8099 - val_loss: 0.1889 - val_precision: 0.5565 - val_recall: 0.1616\n",
            "Epoch 11/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3960 - auc: 0.8015 - loss: 0.1944 - precision: 0.6174 - recall: 0.1590\n",
            "Epoch 11: val_auc did not improve from 0.82944\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.3958 - auc: 0.8015 - loss: 0.1945 - precision: 0.6173 - recall: 0.1589 - val_accuracy: 0.3281 - val_auc: 0.7929 - val_loss: 0.1964 - val_precision: 0.3750 - val_recall: 0.0076\n",
            "Epoch 12/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3539 - auc: 0.8002 - loss: 0.1966 - precision: 0.5999 - recall: 0.1218\n",
            "Epoch 12: val_auc did not improve from 0.82944\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.3541 - auc: 0.8003 - loss: 0.1966 - precision: 0.5995 - recall: 0.1219 - val_accuracy: 0.4031 - val_auc: 0.8225 - val_loss: 0.1900 - val_precision: 0.5338 - val_recall: 0.1793\n",
            "Epoch 13/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3429 - auc: 0.8046 - loss: 0.1962 - precision: 0.5316 - recall: 0.1258\n",
            "Epoch 13: val_auc did not improve from 0.82944\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.3432 - auc: 0.8047 - loss: 0.1962 - precision: 0.5322 - recall: 0.1260 - val_accuracy: 0.3906 - val_auc: 0.8210 - val_loss: 0.1853 - val_precision: 0.5176 - val_recall: 0.2601\n",
            "Epoch 14/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4124 - auc: 0.8152 - loss: 0.1883 - precision: 0.6195 - recall: 0.1778\n",
            "Epoch 14: val_auc did not improve from 0.82944\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4122 - auc: 0.8151 - loss: 0.1884 - precision: 0.6195 - recall: 0.1776 - val_accuracy: 0.3438 - val_auc: 0.8125 - val_loss: 0.1913 - val_precision: 0.5563 - val_recall: 0.2121\n",
            "Epoch 15/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3828 - auc: 0.8132 - loss: 0.1914 - precision: 0.5823 - recall: 0.1459\n",
            "Epoch 15: val_auc did not improve from 0.82944\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.3830 - auc: 0.8132 - loss: 0.1914 - precision: 0.5828 - recall: 0.1462 - val_accuracy: 0.4062 - val_auc: 0.7925 - val_loss: 0.1976 - val_precision: 0.4952 - val_recall: 0.2626\n",
            "Epoch 16/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4278 - auc: 0.8184 - loss: 0.1883 - precision: 0.6033 - recall: 0.1786\n",
            "Epoch 16: val_auc improved from 0.82944 to 0.83882, saving model to best_biobert_medical_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 3s/step - accuracy: 0.4277 - auc: 0.8184 - loss: 0.1883 - precision: 0.6033 - recall: 0.1785 - val_accuracy: 0.4344 - val_auc: 0.8388 - val_loss: 0.1825 - val_precision: 0.6375 - val_recall: 0.2576\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "Evaluating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.4439 - auc: 0.8596 - loss: 0.1744 - precision: 0.6034 - recall: 0.1460\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 0.1830\n",
            "Test Accuracy: 0.4062\n",
            "Test Precision: 0.5281\n",
            "Test Recall: 0.1158\n",
            "Test AUC: 0.8402\n",
            "Training completed successfully!\n",
            "\n",
            "Architecture Summary:\n",
            "1. Visual Features: DenseNet201 + Multi-scale features → 512-dim vectors\n",
            "2. BioBERT Disease Embeddings → 512-dim vectors\n",
            "3. Combined features fed to Transformer encoders\n",
            "4. Final classification predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IyzwXE6cTKpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # import numpy as np\n",
        "# # import pandas as pd\n",
        "# # import tensorflow as tf\n",
        "# # from tensorflow.keras.applications.densenet import DenseNet201\n",
        "# # from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# # from tensorflow.keras.models import Model\n",
        "# # from tensorflow.keras.optimizers import Adam\n",
        "# # from tensorflow.keras.layers import (Dense, GlobalAveragePooling2D, Conv2D,\n",
        "# #                                    Conv2DTranspose, Reshape, Add, Multiply,\n",
        "# #                                    MultiHeadAttention, LayerNormalization, Dropout,\n",
        "# #                                    Input, Concatenate)\n",
        "# # from tensorflow.keras.metrics import Recall, Precision, AUC\n",
        "# # from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# # from zipfile import ZipFile\n",
        "# # import os\n",
        "\n",
        "# # # Install required packages for BioBERT\n",
        "# # try:\n",
        "# #     import transformers\n",
        "# #     from transformers import AutoTokenizer, TFAutoModel\n",
        "# #     print(\"Transformers library already installed\")\n",
        "# # except ImportError:\n",
        "# #     print(\"Installing transformers library...\")\n",
        "# #     os.system(\"pip install transformers\")\n",
        "# #     import transformers\n",
        "# #     from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "# # # Mount Google Drive (if using Colab)\n",
        "# # try:\n",
        "# #     from google.colab import drive\n",
        "# #     drive.mount('/content/drive')\n",
        "# #     print(\"Google Drive mounted successfully\")\n",
        "# # except ImportError:\n",
        "# #     print(\"Not running in Colab, skipping drive mount\")\n",
        "\n",
        "# # # BioBERT Disease Embedding Class\n",
        "# # class BioBERTDiseaseEmbedder:\n",
        "# #     \"\"\"Class to generate disease embeddings using BioBERT\"\"\"\n",
        "\n",
        "# #     def __init__(self, model_name='dmis-lab/biobert-base-cased-v1.1', embedding_dim=512):\n",
        "# #         self.model_name = model_name\n",
        "# #         self.embedding_dim = embedding_dim\n",
        "# #         self.tokenizer = None\n",
        "# #         self.model = None\n",
        "# #         self.disease_embeddings = None\n",
        "\n",
        "# #     def load_model(self):\n",
        "# #         \"\"\"Load BioBERT tokenizer and model\"\"\"\n",
        "# #         print(\"Loading BioBERT model...\")\n",
        "# #         try:\n",
        "# #             self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "# #             # Try loading with PyTorch conversion first\n",
        "# #             self.model = TFAutoModel.from_pretrained(self.model_name, from_pt=True)\n",
        "# #             print(\"BioBERT model loaded successfully (converted from PyTorch)\")\n",
        "# #         except Exception as e:\n",
        "# #             print(f\"Error loading BioBERT model: {e}\")\n",
        "# #             print(\"Falling back to alternative biomedical model...\")\n",
        "# #             # Fallback to a model with native TensorFlow support\n",
        "# #             try:\n",
        "# #                 self.model_name = 'bert-base-uncased'  # Fallback option\n",
        "# #                 self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "# #                 self.model = TFAutoModel.from_pretrained(self.model_name)\n",
        "# #                 print(\"Fallback model loaded successfully\")\n",
        "# #             except Exception as e2:\n",
        "# #                 print(f\"Fallback model also failed: {e2}\")\n",
        "# #                 raise e2\n",
        "\n",
        "# #     def generate_disease_embeddings(self, disease_labels):\n",
        "# #         \"\"\"Generate embeddings for disease labels\"\"\"\n",
        "# #         if self.tokenizer is None or self.model is None:\n",
        "# #             self.load_model()\n",
        "\n",
        "# #         embeddings = []\n",
        "\n",
        "# #         print(\"Generating disease embeddings...\")\n",
        "# #         for disease in disease_labels:\n",
        "# #             # Tokenize the disease name\n",
        "# #             inputs = self.tokenizer(\n",
        "# #                 disease,\n",
        "# #                 return_tensors='tf',\n",
        "# #                 padding=True,\n",
        "# #                 truncation=True,\n",
        "# #                 max_length=64\n",
        "# #             )\n",
        "\n",
        "# #             # Get BioBERT embeddings\n",
        "# #             outputs = self.model(**inputs)\n",
        "\n",
        "# #             # Use [CLS] token embedding (first token)\n",
        "# #             cls_embedding = outputs.last_hidden_state[:, 0, :]  # Shape: (1, 768)\n",
        "\n",
        "# #             embeddings.append(cls_embedding.numpy())\n",
        "\n",
        "# #         # Stack all embeddings\n",
        "# #         disease_embeddings = np.vstack(embeddings)  # Shape: (num_diseases, 768)\n",
        "\n",
        "# #         # Project to desired embedding dimension if needed\n",
        "# #         if disease_embeddings.shape[1] != self.embedding_dim:\n",
        "# #             projection_matrix = np.random.normal(\n",
        "# #                 0, 0.02, (disease_embeddings.shape[1], self.embedding_dim)\n",
        "# #             )\n",
        "# #             disease_embeddings = disease_embeddings @ projection_matrix\n",
        "\n",
        "# #         self.disease_embeddings = disease_embeddings\n",
        "# #         print(f\"Disease embeddings generated: {disease_embeddings.shape}\")\n",
        "\n",
        "# #         return disease_embeddings\n",
        "\n",
        "# # # Data extraction\n",
        "# # def extract_data():\n",
        "# #     \"\"\"Extract dataset from zip file\"\"\"\n",
        "# #     try:\n",
        "# #         with ZipFile(\"/content/drive/MyDrive/mured.zip\", 'r') as zip_file:\n",
        "# #             zip_file.extractall()\n",
        "# #             print(\"Data extraction completed\")\n",
        "# #     except FileNotFoundError:\n",
        "# #         print(\"Warning: Zip file not found. Please ensure data is available.\")\n",
        "\n",
        "# # # Data loading and preprocessing\n",
        "# # def load_and_prepare_data():\n",
        "# #     \"\"\"Load and prepare training and test data\"\"\"\n",
        "# #     try:\n",
        "# #         # Load data\n",
        "# #         train_data = pd.read_csv('/content/drive/MyDrive/train_data_modified.csv')\n",
        "# #         test_data = pd.read_csv('/content/drive/MyDrive/test_data_modified.csv')\n",
        "\n",
        "# #         # Sample data for training (adjust as needed)\n",
        "# #         train_data = train_data.sample(frac=1, random_state=42)[:1600]\n",
        "# #         test_data = test_data[:320]\n",
        "\n",
        "# #         print(f\"Training data shape: {train_data.shape}\")\n",
        "# #         print(f\"Test data shape: {test_data.shape}\")\n",
        "\n",
        "# #         return train_data, test_data\n",
        "# #     except FileNotFoundError:\n",
        "# #         print(\"Error: CSV files not found. Please check file paths.\")\n",
        "# #         return None, None\n",
        "\n",
        "# # # Define disease labels\n",
        "# # DISEASE_LABELS = ['DR', 'NORMAL', 'MH', 'ODC', 'TSLN', 'ARMD', 'DN', 'MYA',\n",
        "# #                   'BRVO', 'ODP', 'CRVO', 'CNV', 'RS', 'ODE', 'LS', 'CSR',\n",
        "# #                   'HTR', 'ASR', 'CRS', 'OTHER']\n",
        "\n",
        "# # DISEASE_LABELS_FULL = ['DIABETIC RETINOPATHY', 'NORMAL', 'MEDIA HAZE',\n",
        "# #                        'OPTIC DISC COLOBOMA', 'TESSELLATION',\n",
        "# #                        'AGE RELATED MACULAR DEGENERATION', 'DRUSEN', 'MYOPIA',\n",
        "# #                        'BRANCH RETINAL VEIN OCCLUSION', 'OPTIC DISC PALLOR',\n",
        "# #                        'CENTRAL RETINAL VEIN OCCLUSION', 'CHOROIDAL NEOVASCULARIZATION',\n",
        "# #                        'RETINITIS', 'OPTIC DISC EDEMA', 'LASER SCARS',\n",
        "# #                        'CENTRAL SEROUS RETINOPATHY', 'HYPERTENSIVE RETINOPATHY',\n",
        "# #                        'ARTIFICIAL SILICON RETINA', 'CHORIORETINITIS', 'OTHER']\n",
        "\n",
        "# # # Data generators\n",
        "# # def create_data_generators(train_data, test_data, batch_size=16, img_size=(320, 320)):\n",
        "# #     \"\"\"Create data generators for training, validation, and testing\"\"\"\n",
        "\n",
        "# #     # Training data generator with augmentation\n",
        "# #     train_datagen = ImageDataGenerator(\n",
        "# #         rescale=1./255,\n",
        "# #         validation_split=0.2,\n",
        "# #         rotation_range=40,\n",
        "# #         width_shift_range=0.2,\n",
        "# #         height_shift_range=0.2,\n",
        "# #         shear_range=0.2,\n",
        "# #         zoom_range=0.2,\n",
        "# #         horizontal_flip=True,\n",
        "# #         fill_mode='nearest'\n",
        "# #     )\n",
        "\n",
        "# #     # Test data generator (no augmentation)\n",
        "# #     test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# #     train_generator = train_datagen.flow_from_dataframe(\n",
        "# #         dataframe=train_data,\n",
        "# #         directory=\"/content/images/images\",\n",
        "# #         x_col=\"ID_2\",\n",
        "# #         y_col=DISEASE_LABELS,\n",
        "# #         class_mode='raw',\n",
        "# #         batch_size=batch_size,\n",
        "# #         target_size=img_size,\n",
        "# #         subset='training'\n",
        "# #     )\n",
        "\n",
        "# #     val_generator = train_datagen.flow_from_dataframe(\n",
        "# #         dataframe=train_data,\n",
        "# #         directory=\"/content/images/images\",\n",
        "# #         x_col=\"ID_2\",\n",
        "# #         y_col=DISEASE_LABELS,\n",
        "# #         class_mode='raw',\n",
        "# #         batch_size=batch_size,\n",
        "# #         target_size=img_size,\n",
        "# #         subset='validation'\n",
        "# #     )\n",
        "\n",
        "# #     test_generator = test_datagen.flow_from_dataframe(\n",
        "# #         dataframe=test_data,\n",
        "# #         directory=\"/content/images/images\",\n",
        "# #         x_col=\"ID_2\",\n",
        "# #         y_col=DISEASE_LABELS,\n",
        "# #         class_mode='raw',\n",
        "# #         batch_size=batch_size,\n",
        "# #         target_size=img_size,\n",
        "# #         shuffle=False\n",
        "# #     )\n",
        "\n",
        "# #     return train_generator, val_generator, test_generator\n",
        "\n",
        "# # # Custom layers\n",
        "# # class FullyConnectedLayer(tf.keras.layers.Layer):\n",
        "# #     \"\"\"Custom fully connected layer for transformer-like architecture\"\"\"\n",
        "\n",
        "# #     def __init__(self, embedding_dim, fully_connected_dim, dropout_rate=0.1, **kwargs):\n",
        "# #         super(FullyConnectedLayer, self).__init__(**kwargs)\n",
        "# #         self.embedding_dim = embedding_dim\n",
        "# #         self.fully_connected_dim = fully_connected_dim\n",
        "# #         self.dropout_rate = dropout_rate\n",
        "\n",
        "# #         self.dense1 = Dense(fully_connected_dim, activation='relu')\n",
        "# #         self.dense2 = Dense(embedding_dim)\n",
        "# #         self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "# #     def call(self, x, training=False):\n",
        "# #         x = self.dense1(x)\n",
        "# #         x = self.dropout(x, training=training)\n",
        "# #         return self.dense2(x)\n",
        "\n",
        "# #     def get_config(self):\n",
        "# #         config = super().get_config()\n",
        "# #         config.update({\n",
        "# #             \"embedding_dim\": self.embedding_dim,\n",
        "# #             \"fully_connected_dim\": self.fully_connected_dim,\n",
        "# #             \"dropout_rate\": self.dropout_rate\n",
        "# #         })\n",
        "# #         return config\n",
        "\n",
        "# # class EncoderLayer(tf.keras.layers.Layer):\n",
        "# #     \"\"\"Transformer encoder layer with multi-head attention\"\"\"\n",
        "\n",
        "# #     def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
        "# #                  dropout_rate=0.1, **kwargs):\n",
        "# #         super(EncoderLayer, self).__init__(**kwargs)\n",
        "\n",
        "# #         self.embedding_dim = embedding_dim\n",
        "# #         self.num_heads = num_heads\n",
        "# #         self.fully_connected_dim = fully_connected_dim\n",
        "# #         self.dropout_rate = dropout_rate\n",
        "\n",
        "# #         self.mha = MultiHeadAttention(\n",
        "# #             num_heads=num_heads,\n",
        "# #             key_dim=embedding_dim,\n",
        "# #             dropout=dropout_rate\n",
        "# #         )\n",
        "\n",
        "# #         self.ffn = FullyConnectedLayer(embedding_dim, fully_connected_dim, dropout_rate)\n",
        "# #         self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "# #         self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "# #         self.dropout1 = Dropout(dropout_rate)\n",
        "\n",
        "# #     def call(self, inputs, training=False):\n",
        "# #         # Multi-head attention\n",
        "# #         attn_output = self.mha(inputs, inputs, inputs, training=training)\n",
        "# #         attn_output = self.dropout1(attn_output, training=training)\n",
        "# #         out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "# #         # Feed forward network\n",
        "# #         ffn_output = self.ffn(out1, training=training)\n",
        "# #         encoder_output = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# #         return encoder_output\n",
        "\n",
        "# #     def get_config(self):\n",
        "# #         config = super().get_config()\n",
        "# #         config.update({\n",
        "# #             \"embedding_dim\": self.embedding_dim,\n",
        "# #             \"num_heads\": self.num_heads,\n",
        "# #             \"fully_connected_dim\": self.fully_connected_dim,\n",
        "# #             \"dropout_rate\": self.dropout_rate\n",
        "# #         })\n",
        "# #         return config\n",
        "\n",
        "# # class GlobalMeanPoolingLayer(tf.keras.layers.Layer):\n",
        "# #     \"\"\"Custom layer for global mean pooling along sequence dimension\"\"\"\n",
        "\n",
        "# #     def __init__(self, **kwargs):\n",
        "# #         super(GlobalMeanPoolingLayer, self).__init__(**kwargs)\n",
        "\n",
        "# #     def call(self, inputs):\n",
        "# #         return tf.reduce_mean(inputs, axis=1)\n",
        "\n",
        "# #     def get_config(self):\n",
        "# #         return super().get_config()\n",
        "\n",
        "# # class DiseaseEmbeddingExpansionLayer(tf.keras.layers.Layer):\n",
        "# #     \"\"\"Layer to expand disease embeddings based on batch size\"\"\"\n",
        "\n",
        "# #     def __init__(self, num_classes, **kwargs):\n",
        "# #         super(DiseaseEmbeddingExpansionLayer, self).__init__(**kwargs)\n",
        "# #         self.num_classes = num_classes\n",
        "\n",
        "# #     def call(self, inputs):\n",
        "# #         # inputs is a tuple of (batch_reference, disease_embeddings)\n",
        "# #         batch_reference, disease_embeddings = inputs\n",
        "# #         batch_size = tf.shape(batch_reference)[0]\n",
        "\n",
        "# #         # Expand disease embeddings to match batch size\n",
        "# #         expanded = tf.expand_dims(disease_embeddings, 0)\n",
        "# #         tiled = tf.tile(expanded, [batch_size, 1, 1])\n",
        "# #         return tiled\n",
        "\n",
        "# #     def get_config(self):\n",
        "# #         config = super().get_config()\n",
        "# #         config.update({\"num_classes\": self.num_classes})\n",
        "# #         return config\n",
        "# #     \"\"\"Layer to provide BioBERT disease embeddings to the model\"\"\"\n",
        "\n",
        "# #     def __init__(self, disease_embeddings, embedding_dim=512, **kwargs):\n",
        "# #         super(BioBERTDiseaseEmbeddingLayer, self).__init__(**kwargs)\n",
        "# #         self.embedding_dim = embedding_dim\n",
        "# #         self.num_classes = disease_embeddings.shape[0]\n",
        "\n",
        "# #         # Store disease embeddings as a weight (trainable parameter)\n",
        "# #         self.disease_embeddings_weight = None\n",
        "# #         self.disease_embeddings_np = disease_embeddings.astype(np.float32)\n",
        "\n",
        "# #     def build(self, input_shape):\n",
        "# #         # Create the embeddings as a trainable weight\n",
        "# #         self.disease_embeddings_weight = self.add_weight(\n",
        "# #             name='disease_embeddings',\n",
        "# #             shape=(self.num_classes, self.embedding_dim),\n",
        "# #             initializer='zeros',\n",
        "# #             trainable=False  # Keep as non-trainable since they're pre-computed\n",
        "# #         )\n",
        "# #         # Initialize with BioBERT embeddings\n",
        "# #         self.disease_embeddings_weight.assign(self.disease_embeddings_np)\n",
        "# #         super().build(input_shape)\n",
        "\n",
        "# #     def call(self, inputs):\n",
        "# #         # Get batch size from input tensor\n",
        "# #         batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "# #         # Expand disease embeddings to match batch size\n",
        "# #         # Shape: (num_classes, embedding_dim) -> (batch_size, num_classes, embedding_dim)\n",
        "# #         expanded_embeddings = tf.expand_dims(self.disease_embeddings_weight, 0)\n",
        "# #         tiled_embeddings = tf.tile(expanded_embeddings, [batch_size, 1, 1])\n",
        "\n",
        "# #         return tiled_embeddings\n",
        "\n",
        "# #     def get_config(self):\n",
        "# #         config = super().get_config()\n",
        "# #         config.update({\n",
        "# #             \"embedding_dim\": self.embedding_dim,\n",
        "# #             \"num_classes\": self.num_classes\n",
        "# #         })\n",
        "# #         return config\n",
        "\n",
        "# # # Model building functions\n",
        "# # def create_base_model(input_shape=(320, 320, 3)):\n",
        "# #     \"\"\"Create base DenseNet201 model\"\"\"\n",
        "# #     base_model = DenseNet201(\n",
        "# #         include_top=False,\n",
        "# #         weights='imagenet',\n",
        "# #         input_shape=input_shape\n",
        "# #     )\n",
        "# #     return base_model\n",
        "\n",
        "# # def create_multi_scale_features(base_model):\n",
        "# #     \"\"\"Create multi-scale feature extraction\"\"\"\n",
        "\n",
        "# #     # Get features from different layers\n",
        "# #     high_level_features = base_model.output  # Shape: (batch, 10, 10, 1920)\n",
        "# #     low_level_output = base_model.layers[-228].output  # Shape: (batch, 20, 20, 1792)\n",
        "\n",
        "# #     # Create models for different feature levels\n",
        "# #     low_level_model = Model(inputs=base_model.input, outputs=low_level_output)\n",
        "\n",
        "# #     # Multi-Scale Feature Module (MSFM)\n",
        "# #     f_h = Conv2D(512, (1, 1), activation='relu', name='high_level_conv')(high_level_features)\n",
        "# #     f_l = Conv2D(512, (1, 1), activation='relu', name='low_level_conv')(low_level_output)\n",
        "\n",
        "# #     # Upsample high-level features\n",
        "# #     f_up = Conv2DTranspose(512, kernel_size=(4, 4), strides=(2, 2),\n",
        "# #                           padding='same', activation='relu', name='upsample')(f_h)\n",
        "\n",
        "# #     # Combine features\n",
        "# #     f_combined = Add(name='feature_add')([f_up, f_l])\n",
        "# #     f_refined = Conv2D(512, 3, padding='same', activation='relu', name='refined_conv')(f_combined)\n",
        "\n",
        "# #     # Channel Attention Module (CAM)\n",
        "# #     f_gap = GlobalAveragePooling2D()(f_refined)\n",
        "# #     f_gap_reshaped = Reshape((1, 1, 512))(f_gap)\n",
        "\n",
        "# #     f_attention = Conv2D(512, (1, 1), activation='relu')(f_gap_reshaped)\n",
        "# #     f_attention = Conv2D(512, (1, 1), activation='sigmoid')(f_attention)\n",
        "\n",
        "# #     f_attended = Multiply()([f_refined, f_attention])\n",
        "# #     f_final = Add()([f_refined, f_attended])\n",
        "\n",
        "# #     return f_final, f_h\n",
        "\n",
        "# # def create_biobert_enhanced_model(input_shape=(320, 320, 3), num_classes=20, disease_embeddings=None):\n",
        "# #     \"\"\"Create the complete model with BioBERT disease embeddings\"\"\"\n",
        "\n",
        "# #     # Input layer\n",
        "# #     image_input = Input(shape=input_shape, name='image_input')\n",
        "\n",
        "# #     # Base DenseNet201 for visual features\n",
        "# #     base_model = DenseNet201(\n",
        "# #         include_top=False,\n",
        "# #         weights='imagenet',\n",
        "# #         input_shape=input_shape\n",
        "# #     )\n",
        "\n",
        "# #     # Get visual features\n",
        "# #     visual_features = base_model(image_input)\n",
        "\n",
        "# #     # Multi-scale feature processing\n",
        "# #     f_h = Conv2D(512, (1, 1), activation='relu', name='high_level_conv')(visual_features)\n",
        "\n",
        "# #     # Try to get low-level features (with error handling)\n",
        "# #     try:\n",
        "# #         low_level_output = base_model.layers[-228].output\n",
        "# #         low_level_model = Model(inputs=base_model.input, outputs=low_level_output)\n",
        "# #         low_level_features = low_level_model(image_input)\n",
        "# #         f_l = Conv2D(512, (1, 1), activation='relu', name='low_level_conv')(low_level_features)\n",
        "\n",
        "# #         # Upsample high-level features\n",
        "# #         f_up = Conv2DTranspose(512, kernel_size=(4, 4), strides=(2, 2),\n",
        "# #                               padding='same', activation='relu', name='upsample')(f_h)\n",
        "\n",
        "# #         # Combine features\n",
        "# #         f_combined = Add(name='feature_add')([f_up, f_l])\n",
        "# #         f_refined = Conv2D(512, 3, padding='same', activation='relu', name='refined_conv')(f_combined)\n",
        "# #     except:\n",
        "# #         # Fallback: just use high-level features\n",
        "# #         print(\"Warning: Could not access low-level features, using high-level only\")\n",
        "# #         f_refined = Conv2D(512, 3, padding='same', activation='relu', name='refined_conv')(f_h)\n",
        "\n",
        "# #     # Global pooling to get visual feature vector\n",
        "# #     visual_pooled = GlobalAveragePooling2D(name='visual_gap')(f_refined)\n",
        "\n",
        "# #     # Reshape visual features for transformer: (batch_size, 1, 512)\n",
        "# #     visual_reshaped = Reshape((1, 512), name='visual_reshape')(visual_pooled)\n",
        "\n",
        "# #     # BioBERT Disease Embeddings\n",
        "# #     if disease_embeddings is not None:\n",
        "# #         # Create a constant layer for disease embeddings\n",
        "# #         disease_embeddings_const = tf.constant(disease_embeddings.astype(np.float32))\n",
        "\n",
        "# #         # Create a layer to expand disease embeddings based on batch size\n",
        "# #         class DiseaseEmbeddingLayer(tf.keras.layers.Layer):\n",
        "# #             def __init__(self, embeddings, **kwargs):\n",
        "# #                 super().__init__(**kwargs)\n",
        "# #                 self.embeddings = embeddings\n",
        "\n",
        "# #             def call(self, inputs):\n",
        "# #                 batch_size = tf.shape(inputs)[0]\n",
        "# #                 expanded = tf.expand_dims(self.embeddings, 0)\n",
        "# #                 return tf.tile(expanded, [batch_size, 1, 1])\n",
        "\n",
        "# #         disease_embedding_layer = DiseaseEmbeddingLayer(disease_embeddings_const, name='disease_embeddings')\n",
        "# #         disease_features = disease_embedding_layer(image_input)\n",
        "# #     else:\n",
        "# #         # Fallback to learnable embeddings\n",
        "# #         embedding_layer = tf.keras.layers.Embedding(num_classes, 512, name='learnable_disease_embeddings')\n",
        "# #         indices = tf.range(num_classes)\n",
        "\n",
        "# #         # Create a layer to handle the embedding expansion\n",
        "# #         class LearnableEmbeddingLayer(tf.keras.layers.Layer):\n",
        "# #             def __init__(self, embedding_layer, indices, **kwargs):\n",
        "# #                 super().__init__(**kwargs)\n",
        "# #                 self.embedding_layer = embedding_layer\n",
        "# #                 self.indices = indices\n",
        "\n",
        "# #             def call(self, inputs):\n",
        "# #                 batch_size = tf.shape(inputs)[0]\n",
        "# #                 embeddings = self.embedding_layer(self.indices)\n",
        "# #                 expanded = tf.expand_dims(embeddings, 0)\n",
        "# #                 return tf.tile(expanded, [batch_size, 1, 1])\n",
        "\n",
        "# #         learnable_layer = LearnableEmbeddingLayer(embedding_layer, indices, name='learnable_expansion')\n",
        "# #         disease_features = learnable_layer(image_input)\n",
        "\n",
        "# #     # Concatenate visual and disease features\n",
        "# #     combined_features = Concatenate(axis=1, name='feature_concat')([visual_reshaped, disease_features])\n",
        "\n",
        "# #     # Transformer encoder layers\n",
        "# #     transformer1 = EncoderLayer(\n",
        "# #         embedding_dim=512,\n",
        "# #         num_heads=8,\n",
        "# #         fully_connected_dim=2048,\n",
        "# #         dropout_rate=0.1,\n",
        "# #         name='transformer_encoder_1'\n",
        "# #     )\n",
        "# #     encoded_features1 = transformer1(combined_features)\n",
        "\n",
        "# #     # Second transformer layer\n",
        "# #     transformer2 = EncoderLayer(\n",
        "# #         embedding_dim=512,\n",
        "# #         num_heads=8,\n",
        "# #         fully_connected_dim=2048,\n",
        "# #         dropout_rate=0.1,\n",
        "# #         name='transformer_encoder_2'\n",
        "# #     )\n",
        "# #     encoded_features2 = transformer2(encoded_features1)\n",
        "\n",
        "# #     # Global pooling of all tokens using custom layer\n",
        "# #     global_pool = GlobalMeanPoolingLayer(name='global_mean_pool')\n",
        "# #     final_features = global_pool(encoded_features2)\n",
        "\n",
        "# #     # Classification head\n",
        "# #     x = Dense(1024, activation='relu', name='classifier_dense1')(final_features)\n",
        "# #     x = Dropout(0.5, name='classifier_dropout1')(x)\n",
        "# #     x = Dense(512, activation='relu', name='classifier_dense2')(x)\n",
        "# #     x = Dropout(0.3, name='classifier_dropout2')(x)\n",
        "# #     x = Dense(256, activation='relu', name='classifier_dense3')(x)\n",
        "# #     x = Dropout(0.2, name='classifier_dropout3')(x)\n",
        "\n",
        "# #     # Final predictions\n",
        "# #     predictions = Dense(num_classes, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "# #     # Create final model\n",
        "# #     model = Model(inputs=image_input, outputs=predictions, name='BioBERT_Medical_Classifier')\n",
        "\n",
        "# #     return model\n",
        "\n",
        "# # def create_complete_model(input_shape=(320, 320, 3), num_classes=20, disease_embeddings=None):\n",
        "# #     \"\"\"Create the complete model with BioBERT integration\"\"\"\n",
        "# #     return create_biobert_enhanced_model(input_shape, num_classes, disease_embeddings)\n",
        "\n",
        "# # def compile_model(model, learning_rate=0.001):\n",
        "# #     \"\"\"Compile the model with appropriate optimizer and metrics\"\"\"\n",
        "\n",
        "# #     model.compile(\n",
        "# #         optimizer=Adam(learning_rate=learning_rate),\n",
        "# #         loss='binary_crossentropy',\n",
        "# #         metrics=[\n",
        "# #             'accuracy',\n",
        "# #             Precision(name='precision'),\n",
        "# #             Recall(name='recall'),\n",
        "# #             AUC(name='auc')\n",
        "# #         ]\n",
        "# #     )\n",
        "\n",
        "# #     return model\n",
        "\n",
        "# # def create_callbacks(model_save_path='best_biobert_model.h5'):\n",
        "# #     \"\"\"Create training callbacks\"\"\"\n",
        "\n",
        "# #     callbacks = [\n",
        "# #         EarlyStopping(\n",
        "# #             monitor='val_loss',\n",
        "# #             patience=7,\n",
        "# #             restore_best_weights=True,\n",
        "# #             verbose=1\n",
        "# #         ),\n",
        "# #         ModelCheckpoint(\n",
        "# #             model_save_path,\n",
        "# #             monitor='val_auc',\n",
        "# #             save_best_only=True,\n",
        "# #             mode='max',\n",
        "# #             verbose=1\n",
        "# #         )\n",
        "# #     ]\n",
        "\n",
        "# #     return callbacks\n",
        "\n",
        "# # def train_model(model, train_gen, val_gen, epochs=50, callbacks=None):\n",
        "# #     \"\"\"Train the model\"\"\"\n",
        "\n",
        "# #     history = model.fit(\n",
        "# #         train_gen,\n",
        "# #         steps_per_epoch=len(train_gen),\n",
        "# #         epochs=epochs,\n",
        "# #         validation_data=val_gen,\n",
        "# #         validation_steps=len(val_gen),\n",
        "# #         callbacks=callbacks,\n",
        "# #         verbose=1\n",
        "# #     )\n",
        "\n",
        "# #     return history\n",
        "\n",
        "# # def evaluate_model(model, test_gen):\n",
        "# #     \"\"\"Evaluate the model on test data\"\"\"\n",
        "\n",
        "# #     test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(\n",
        "# #         test_gen,\n",
        "# #         steps=len(test_gen),\n",
        "# #         verbose=1\n",
        "# #     )\n",
        "\n",
        "# #     print(f\"\\nTest Results:\")\n",
        "# #     print(f\"Test Loss: {test_loss:.4f}\")\n",
        "# #     print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "# #     print(f\"Test Precision: {test_precision:.4f}\")\n",
        "# #     print(f\"Test Recall: {test_recall:.4f}\")\n",
        "# #     print(f\"Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "# #     return {\n",
        "# #         'test_loss': test_loss,\n",
        "# #         'test_accuracy': test_accuracy,\n",
        "# #         'test_precision': test_precision,\n",
        "# #         'test_recall': test_recall,\n",
        "# #         'test_auc': test_auc\n",
        "# #     }\n",
        "\n",
        "# # # Main execution function\n",
        "# # def main():\n",
        "# #     \"\"\"Main function to run the complete pipeline with BioBERT\"\"\"\n",
        "\n",
        "# #     print(\"Starting Medical Image Classification Pipeline with BioBERT...\")\n",
        "\n",
        "# #     # Extract data\n",
        "# #     extract_data()\n",
        "\n",
        "# #     # Load and prepare data\n",
        "# #     train_data, test_data = load_and_prepare_data()\n",
        "# #     if train_data is None or test_data is None:\n",
        "# #         print(\"Failed to load data. Exiting.\")\n",
        "# #         return\n",
        "\n",
        "# #     # Generate BioBERT disease embeddings\n",
        "# #     print(\"Generating BioBERT disease embeddings...\")\n",
        "# #     biobert_embedder = BioBERTDiseaseEmbedder(embedding_dim=512)\n",
        "# #     disease_embeddings = biobert_embedder.generate_disease_embeddings(DISEASE_LABELS_FULL)\n",
        "\n",
        "# #     # Create data generators\n",
        "# #     train_gen, val_gen, test_gen = create_data_generators(train_data, test_data)\n",
        "\n",
        "# #     print(\"Data generators created successfully\")\n",
        "# #     print(f\"Training samples: {train_gen.n}\")\n",
        "# #     print(f\"Validation samples: {val_gen.n}\")\n",
        "# #     print(f\"Test samples: {test_gen.n}\")\n",
        "\n",
        "# #     # Create and compile model with BioBERT embeddings\n",
        "# #     print(\"Creating BioBERT-enhanced model...\")\n",
        "# #     model = create_complete_model(\n",
        "# #         input_shape=(320, 320, 3),\n",
        "# #         num_classes=20,\n",
        "# #         disease_embeddings=disease_embeddings\n",
        "# #     )\n",
        "# #     model = compile_model(model, learning_rate=0.0001)  # Lower learning rate for stability\n",
        "\n",
        "# #     print(\"Model created and compiled successfully\")\n",
        "# #     print(f\"Model parameters: {model.count_params():,}\")\n",
        "\n",
        "# #     # Print model summary\n",
        "# #     model.summary()\n",
        "\n",
        "# #     # Create callbacks\n",
        "# #     callbacks = create_callbacks('best_biobert_medical_model.h5')\n",
        "\n",
        "# #     # Train model\n",
        "# #     print(\"Starting training...\")\n",
        "# #     history = train_model(\n",
        "# #         model,\n",
        "# #         train_gen,\n",
        "# #         val_gen,\n",
        "# #         epochs=30,\n",
        "# #         callbacks=callbacks\n",
        "# #     )\n",
        "\n",
        "# #     # Evaluate model\n",
        "# #     print(\"Evaluating model...\")\n",
        "# #     test_results = evaluate_model(model, test_gen)\n",
        "\n",
        "# #     print(\"Training completed successfully!\")\n",
        "# #     print(\"\\nArchitecture Summary:\")\n",
        "# #     print(\"1. Visual Features: DenseNet201 + Multi-scale features → 512-dim vectors\")\n",
        "# #     print(\"2. BioBERT Disease Embeddings → 512-dim vectors\")\n",
        "# #     print(\"3. Combined features fed to Transformer encoders\")\n",
        "# #     print(\"4. Final classification predictions\")\n",
        "\n",
        "# #     return model, history, test_results, disease_embeddings\n",
        "\n",
        "# # # Run the pipeline\n",
        "# # if __name__ == \"__main__\":\n",
        "# #     model, history, results, embeddings = main()\n",
        "\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.models import load_model\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.patches as patches\n",
        "# from google.colab import files\n",
        "# from PIL import Image, ImageDraw, ImageFont\n",
        "# import io\n",
        "# import cv2\n",
        "\n",
        "# # Disease labels (same as in training)\n",
        "# DISEASE_LABELS = ['DR', 'NORMAL', 'MH', 'ODC', 'TSLN', 'ARMD', 'DN', 'MYA',\n",
        "#                   'BRVO', 'ODP', 'CRVO', 'CNV', 'RS', 'ODE', 'LS', 'CSR',\n",
        "#                   'HTR', 'ASR', 'CRS', 'OTHER']\n",
        "\n",
        "# DISEASE_LABELS_FULL = ['DIABETIC RETINOPATHY', 'NORMAL', 'MEDIA HAZE',\n",
        "#                        'OPTIC DISC COLOBOMA', 'TESSELLATION',\n",
        "#                        'AGE RELATED MACULAR DEGENERATION', 'DRUSEN', 'MYOPIA',\n",
        "#                        'BRANCH RETINAL VEIN OCCLUSION', 'OPTIC DISC PALLOR',\n",
        "#                        'CENTRAL RETINAL VEIN OCCLUSION', 'CHOROIDAL NEOVASCULARIZATION',\n",
        "#                        'RETINITIS', 'OPTIC DISC EDEMA', 'LASER SCARS',\n",
        "#                        'CENTRAL SEROUS RETINOPATHY', 'HYPERTENSIVE RETINOPATHY',\n",
        "#                        'ARTIFICIAL SILICON RETINA', 'CHORIORETINITIS', 'OTHER']\n",
        "\n",
        "# # Define color mapping for different disease severity levels\n",
        "# def get_color_for_probability(prob):\n",
        "#     \"\"\"Return color based on probability threshold\"\"\"\n",
        "#     if prob >= 0.8:\n",
        "#         return '#FF4444'  # High probability - Red\n",
        "#     elif prob >= 0.6:\n",
        "#         return '#FF8800'  # Medium-high probability - Orange\n",
        "#     elif prob >= 0.4:\n",
        "#         return '#FFCC00'  # Medium probability - Yellow\n",
        "#     elif prob >= 0.2:\n",
        "#         return '#88CC00'  # Low-medium probability - Light green\n",
        "#     else:\n",
        "#         return '#44AA44'  # Low probability - Green\n",
        "\n",
        "# def load_trained_model():\n",
        "#     \"\"\"Load the trained BioBERT model\"\"\"\n",
        "#     try:\n",
        "#         print(\"Loading trained BioBERT model...\")\n",
        "\n",
        "#         # Custom objects for loading the model\n",
        "#         custom_objects = {\n",
        "#             'FullyConnectedLayer': FullyConnectedLayer,\n",
        "#             'EncoderLayer': EncoderLayer,\n",
        "#             'GlobalMeanPoolingLayer': GlobalMeanPoolingLayer,\n",
        "#             'DiseaseEmbeddingExpansionLayer': DiseaseEmbeddingExpansionLayer\n",
        "#         }\n",
        "\n",
        "#         model = load_model('/content/best_biobert_medical_model.h5',\n",
        "#                           custom_objects=custom_objects,\n",
        "#                           compile=False)\n",
        "#         print(\"✅ Model loaded successfully!\")\n",
        "#         return model\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Error loading model: {e}\")\n",
        "#         print(\"Please ensure the model file exists at: /content/best_biobert_medical_model.h5\")\n",
        "#         return None\n",
        "\n",
        "# def preprocess_image(img_path, target_size=(320, 320)):\n",
        "#     \"\"\"Preprocess uploaded image for prediction\"\"\"\n",
        "#     try:\n",
        "#         # Load image\n",
        "#         img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "#         # Convert to array and normalize\n",
        "#         img_array = image.img_to_array(img)\n",
        "#         img_array = np.expand_dims(img_array, axis=0)\n",
        "#         img_array = img_array / 255.0  # Normalize to [0,1]\n",
        "\n",
        "#         return img_array, img\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Error preprocessing image: {e}\")\n",
        "#         return None, None\n",
        "\n",
        "# def create_prediction_visualization(original_img, predictions, probabilities, threshold=0.3):\n",
        "#     \"\"\"Create a comprehensive visualization of predictions\"\"\"\n",
        "\n",
        "#     # Create figure with subplots\n",
        "#     fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "#     fig.suptitle('BioBERT Medical Image Classification Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "#     # 1. Original Image\n",
        "#     axes[0, 0].imshow(original_img)\n",
        "#     axes[0, 0].set_title('Original Retinal Image', fontsize=14, fontweight='bold')\n",
        "#     axes[0, 0].axis('off')\n",
        "\n",
        "#     # 2. Predictions above threshold\n",
        "#     significant_preds = [(label, full_name, prob) for label, full_name, prob in\n",
        "#                         zip(DISEASE_LABELS, DISEASE_LABELS_FULL, probabilities)\n",
        "#                         if prob >= threshold]\n",
        "\n",
        "#     if significant_preds:\n",
        "#         # Sort by probability\n",
        "#         significant_preds.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "#         y_pos = np.arange(len(significant_preds))\n",
        "#         probs = [pred[2] for pred in significant_preds]\n",
        "#         labels = [f\"{pred[0]}\\n({pred[1][:25]}...)\" if len(pred[1]) > 25\n",
        "#                  else f\"{pred[0]}\\n({pred[1]})\" for pred in significant_preds]\n",
        "#         colors = [get_color_for_probability(prob) for prob in probs]\n",
        "\n",
        "#         bars = axes[0, 1].barh(y_pos, probs, color=colors, alpha=0.8)\n",
        "#         axes[0, 1].set_yticks(y_pos)\n",
        "#         axes[0, 1].set_yticklabels(labels, fontsize=10)\n",
        "#         axes[0, 1].set_xlabel('Probability', fontsize=12)\n",
        "#         axes[0, 1].set_title(f'Detected Conditions (≥{threshold})', fontsize=14, fontweight='bold')\n",
        "#         axes[0, 1].set_xlim(0, 1)\n",
        "\n",
        "#         # Add probability values on bars\n",
        "#         for bar, prob in zip(bars, probs):\n",
        "#             axes[0, 1].text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "#                            f'{prob:.3f}', va='center', fontsize=10, fontweight='bold')\n",
        "#     else:\n",
        "#         axes[0, 1].text(0.5, 0.5, 'No significant conditions detected\\n(all probabilities < threshold)',\n",
        "#                        ha='center', va='center', fontsize=12, transform=axes[0, 1].transAxes)\n",
        "#         axes[0, 1].set_title(f'Detected Conditions (≥{threshold})', fontsize=14, fontweight='bold')\n",
        "\n",
        "#     # 3. All predictions heatmap\n",
        "#     prob_matrix = probabilities.reshape(4, 5)  # 4x5 grid for 20 diseases\n",
        "#     label_matrix = np.array(DISEASE_LABELS).reshape(4, 5)\n",
        "\n",
        "#     im = axes[1, 0].imshow(prob_matrix, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=1)\n",
        "#     axes[1, 0].set_title('All Conditions Probability Heatmap', fontsize=14, fontweight='bold')\n",
        "\n",
        "#     # Add labels to heatmap\n",
        "#     for i in range(4):\n",
        "#         for j in range(5):\n",
        "#             text = axes[1, 0].text(j, i, f'{label_matrix[i, j]}\\n{prob_matrix[i, j]:.3f}',\n",
        "#                                   ha=\"center\", va=\"center\", fontsize=9, fontweight='bold')\n",
        "\n",
        "#     axes[1, 0].set_xticks([])\n",
        "#     axes[1, 0].set_yticks([])\n",
        "\n",
        "#     # Add colorbar\n",
        "#     plt.colorbar(im, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
        "\n",
        "#     # 4. Risk Assessment Summary\n",
        "#     axes[1, 1].axis('off')\n",
        "\n",
        "#     # Calculate risk levels\n",
        "#     high_risk = sum(1 for p in probabilities if p >= 0.7)\n",
        "#     medium_risk = sum(1 for p in probabilities if 0.4 <= p < 0.7)\n",
        "#     low_risk = sum(1 for p in probabilities if 0.2 <= p < 0.4)\n",
        "\n",
        "#     # Find top condition\n",
        "#     max_idx = np.argmax(probabilities)\n",
        "#     top_condition = DISEASE_LABELS_FULL[max_idx]\n",
        "#     top_prob = probabilities[max_idx]\n",
        "\n",
        "#     summary_text = f\"\"\"\n",
        "# CLINICAL ASSESSMENT SUMMARY\n",
        "\n",
        "# 🔴 High Risk Conditions (≥70%): {high_risk}\n",
        "# 🟡 Medium Risk Conditions (40-69%): {medium_risk}\n",
        "# 🟢 Low Risk Conditions (20-39%): {low_risk}\n",
        "\n",
        "# 📊 TOP FINDING:\n",
        "# {top_condition}\n",
        "# Confidence: {top_prob:.1%}\n",
        "\n",
        "# ⚠️  CLINICAL NOTES:\n",
        "# • This is an AI-generated assessment\n",
        "# • Requires professional medical evaluation\n",
        "# • Not a substitute for clinical diagnosis\n",
        "# • Consider patient history and symptoms\n",
        "\n",
        "# 📋 RECOMMENDATION:\n",
        "# {'Immediate medical attention recommended' if top_prob > 0.8\n",
        "#  else 'Medical consultation advised' if top_prob > 0.5\n",
        "#  else 'Routine follow-up suggested'}\n",
        "#     \"\"\"\n",
        "\n",
        "#     axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes,\n",
        "#                    fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
        "#                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# def generate_detailed_report(probabilities, threshold=0.2):\n",
        "#     \"\"\"Generate a detailed medical report\"\"\"\n",
        "#     print(\"\\n\" + \"=\"*80)\n",
        "#     print(\"🏥 DETAILED MEDICAL IMAGE ANALYSIS REPORT\")\n",
        "#     print(\"=\"*80)\n",
        "\n",
        "#     # Sort conditions by probability\n",
        "#     condition_data = list(zip(DISEASE_LABELS, DISEASE_LABELS_FULL, probabilities))\n",
        "#     condition_data.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "#     print(f\"\\n📊 FINDINGS SUMMARY:\")\n",
        "#     print(f\"{'Rank':<4} {'Code':<6} {'Condition':<35} {'Confidence':<12} {'Status'}\")\n",
        "#     print(\"-\" * 80)\n",
        "\n",
        "#     for rank, (code, full_name, prob) in enumerate(condition_data, 1):\n",
        "#         if prob >= threshold:\n",
        "#             status = \"🔴 HIGH\" if prob >= 0.7 else \"🟡 MEDIUM\" if prob >= 0.4 else \"🟢 LOW\"\n",
        "#             print(f\"{rank:<4} {code:<6} {full_name:<35} {prob:.1%}{'':>8} {status}\")\n",
        "\n",
        "#     # Clinical interpretation\n",
        "#     print(f\"\\n🩺 CLINICAL INTERPRETATION:\")\n",
        "#     top_condition = condition_data[0]\n",
        "\n",
        "#     if top_condition[2] >= 0.8:\n",
        "#         interpretation = f\"Strong indication of {top_condition[1]} detected.\"\n",
        "#     elif top_condition[2] >= 0.6:\n",
        "#         interpretation = f\"Moderate indication of {top_condition[1]} observed.\"\n",
        "#     elif top_condition[2] >= 0.4:\n",
        "#         interpretation = f\"Mild indication of {top_condition[1]} present.\"\n",
        "#     else:\n",
        "#         interpretation = \"No significant pathological findings detected.\"\n",
        "\n",
        "#     print(f\"• {interpretation}\")\n",
        "\n",
        "#     # Recommendations\n",
        "#     print(f\"\\n💡 RECOMMENDATIONS:\")\n",
        "#     if top_condition[2] >= 0.7:\n",
        "#         print(\"• Immediate ophthalmological consultation recommended\")\n",
        "#         print(\"• Consider advanced imaging (OCT, fluorescein angiography)\")\n",
        "#         print(\"• Monitor for progression and complications\")\n",
        "#     elif top_condition[2] >= 0.4:\n",
        "#         print(\"• Schedule routine ophthalmological follow-up\")\n",
        "#         print(\"• Monitor symptoms and visual changes\")\n",
        "#         print(\"• Consider lifestyle modifications if applicable\")\n",
        "#     else:\n",
        "#         print(\"• Continue routine eye care and regular check-ups\")\n",
        "#         print(\"• Maintain healthy lifestyle habits\")\n",
        "\n",
        "#     print(f\"\\n⚠️  IMPORTANT DISCLAIMERS:\")\n",
        "#     print(\"• This AI analysis is for research/educational purposes only\")\n",
        "#     print(\"• Not intended for clinical diagnosis or treatment decisions\")\n",
        "#     print(\"• Professional medical evaluation is always required\")\n",
        "#     print(\"• Consider patient history, symptoms, and clinical context\")\n",
        "\n",
        "#     print(\"=\"*80)\n",
        "\n",
        "# def predict_single_image():\n",
        "#     \"\"\"Main function for single image prediction\"\"\"\n",
        "\n",
        "#     # Load the trained model\n",
        "#     model = load_trained_model()\n",
        "#     if model is None:\n",
        "#         return\n",
        "\n",
        "#     print(\"\\n🔬 BioBERT Medical Image Classifier\")\n",
        "#     print(\"=\" * 50)\n",
        "#     print(\"Upload a retinal fundus image for analysis...\")\n",
        "\n",
        "#     # Upload image\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     if not uploaded:\n",
        "#         print(\"❌ No image uploaded.\")\n",
        "#         return\n",
        "\n",
        "#     # Process each uploaded image\n",
        "#     for filename, data in uploaded.items():\n",
        "#         print(f\"\\n📸 Processing: {filename}\")\n",
        "#         print(\"-\" * 30)\n",
        "\n",
        "#         # Save uploaded file temporarily\n",
        "#         with open(filename, 'wb') as f:\n",
        "#             f.write(data)\n",
        "\n",
        "#         # Preprocess image\n",
        "#         img_array, original_img = preprocess_image(filename)\n",
        "\n",
        "#         if img_array is None:\n",
        "#             continue\n",
        "\n",
        "#         # Make prediction\n",
        "#         print(\"🤖 Running BioBERT analysis...\")\n",
        "#         try:\n",
        "#             predictions = model.predict(img_array, verbose=0)\n",
        "#             probabilities = predictions[0]  # Get first (and only) sample\n",
        "\n",
        "#             print(\"✅ Analysis complete!\")\n",
        "\n",
        "#             # Create visualization\n",
        "#             create_prediction_visualization(original_img, predictions, probabilities)\n",
        "\n",
        "#             # Generate detailed report\n",
        "#             generate_detailed_report(probabilities)\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ Error during prediction: {e}\")\n",
        "#             print(\"Please check that the model architecture matches the saved model.\")\n",
        "\n",
        "# def predict_batch_images():\n",
        "#     \"\"\"Function for batch image prediction\"\"\"\n",
        "\n",
        "#     # Load the trained model\n",
        "#     model = load_trained_model()\n",
        "#     if model is None:\n",
        "#         return\n",
        "\n",
        "#     print(\"\\n🔬 BioBERT Medical Image Classifier - Batch Mode\")\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Upload multiple retinal fundus images for batch analysis...\")\n",
        "\n",
        "#     # Upload images\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     if not uploaded:\n",
        "#         print(\"❌ No images uploaded.\")\n",
        "#         return\n",
        "\n",
        "#     results_summary = []\n",
        "\n",
        "#     # Process each uploaded image\n",
        "#     for idx, (filename, data) in enumerate(uploaded.items(), 1):\n",
        "#         print(f\"\\n📸 Processing {idx}/{len(uploaded)}: {filename}\")\n",
        "\n",
        "#         # Save uploaded file temporarily\n",
        "#         with open(filename, 'wb') as f:\n",
        "#             f.write(data)\n",
        "\n",
        "#         # Preprocess image\n",
        "#         img_array, original_img = preprocess_image(filename)\n",
        "\n",
        "#         if img_array is None:\n",
        "#             continue\n",
        "\n",
        "#         # Make prediction\n",
        "#         try:\n",
        "#             predictions = model.predict(img_array, verbose=0)\n",
        "#             probabilities = predictions[0]\n",
        "\n",
        "#             # Store results\n",
        "#             top_idx = np.argmax(probabilities)\n",
        "#             top_condition = DISEASE_LABELS_FULL[top_idx]\n",
        "#             top_prob = probabilities[top_idx]\n",
        "\n",
        "#             results_summary.append({\n",
        "#                 'filename': filename,\n",
        "#                 'top_condition': top_condition,\n",
        "#                 'confidence': top_prob,\n",
        "#                 'probabilities': probabilities\n",
        "#             })\n",
        "\n",
        "#             print(f\"✅ Top finding: {top_condition} ({top_prob:.1%})\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ Error processing {filename}: {e}\")\n",
        "\n",
        "#     # Display batch summary\n",
        "#     if results_summary:\n",
        "#         print(\"\\n\" + \"=\"*80)\n",
        "#         print(\"📊 BATCH ANALYSIS SUMMARY\")\n",
        "#         print(\"=\"*80)\n",
        "\n",
        "#         print(f\"{'Image':<25} {'Top Condition':<35} {'Confidence'}\")\n",
        "#         print(\"-\" * 80)\n",
        "\n",
        "#         for result in results_summary:\n",
        "#             print(f\"{result['filename']:<25} {result['top_condition']:<35} {result['confidence']:.1%}\")\n",
        "\n",
        "#         # Create batch visualization\n",
        "#         fig, axes = plt.subplots(2, min(3, len(results_summary)),\n",
        "#                                 figsize=(5*min(3, len(results_summary)), 10))\n",
        "#         if len(results_summary) == 1:\n",
        "#             axes = axes.reshape(-1, 1)\n",
        "\n",
        "#         for i, result in enumerate(results_summary[:3]):  # Show first 3\n",
        "#             if len(results_summary) > 1:\n",
        "#                 col = i\n",
        "#             else:\n",
        "#                 col = 0\n",
        "\n",
        "#             # Load and display image\n",
        "#             img = image.load_img(result['filename'], target_size=(320, 320))\n",
        "#             axes[0, col].imshow(img)\n",
        "#             axes[0, col].set_title(f\"{result['filename'][:15]}...\", fontsize=10)\n",
        "#             axes[0, col].axis('off')\n",
        "\n",
        "#             # Show top predictions\n",
        "#             top_5_idx = np.argsort(result['probabilities'])[-5:][::-1]\n",
        "#             top_5_probs = result['probabilities'][top_5_idx]\n",
        "#             top_5_labels = [DISEASE_LABELS[idx] for idx in top_5_idx]\n",
        "\n",
        "#             axes[1, col].barh(range(5), top_5_probs,\n",
        "#                              color=[get_color_for_probability(p) for p in top_5_probs])\n",
        "#             axes[1, col].set_yticks(range(5))\n",
        "#             axes[1, col].set_yticklabels(top_5_labels)\n",
        "#             axes[1, col].set_xlabel('Probability')\n",
        "#             axes[1, col].set_title('Top 5 Predictions', fontsize=10)\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "\n",
        "# # Main interface\n",
        "# def medical_image_classifier():\n",
        "#     \"\"\"Main interface for the medical image classifier\"\"\"\n",
        "\n",
        "#     print(\"🏥 BioBERT-Enhanced Medical Image Classification System\")\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Choose analysis mode:\")\n",
        "#     print(\"1. Single Image Analysis (detailed)\")\n",
        "#     print(\"2. Batch Image Analysis (multiple images)\")\n",
        "\n",
        "#     try:\n",
        "#         choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "\n",
        "#         if choice == \"1\":\n",
        "#             predict_single_image()\n",
        "#         elif choice == \"2\":\n",
        "#             predict_batch_images()\n",
        "#         else:\n",
        "#             print(\"❌ Invalid choice. Please enter 1 or 2.\")\n",
        "\n",
        "#     except KeyboardInterrupt:\n",
        "#         print(\"\\n⏹️ Analysis cancelled by user.\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Unexpected error: {e}\")\n",
        "\n",
        "# # Run the classifier\n",
        "# print(\"🚀 Ready to analyze retinal images!\")\n",
        "# print(\"Run medical_image_classifier() to start the analysis\")\n",
        "\n",
        "# # Uncomment the line below to run immediately\n",
        "# medical_image_classifier()"
      ],
      "metadata": {
        "id": "cW_08mDkTKmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CP8-rMAVI1Z-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}